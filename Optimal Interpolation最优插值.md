# Optimal Interpolation 最优插值 #

# 概述 #
Optimal interpolation 是一种常用的数据同化方法，用于将理论（背景数据）与观察相结合，可合并和插值来自不同数据源的同一变量（如高程或降雨量）的测量值。例如，可将全球平均海面高度模型输出数据集与特定时间段和位置的更准确海面高度测量值相结合，得到更准确的全球海面高度数据。
## 用法
- 工具输入：需要背景数据集（通常为网格化栅格）和观测数据集（通常为点形式的特征或轨迹数据集）。
- 权重分配：根据背景数据集和观测数据集的相对精度分配权重，以减少分析误差方差。相对精度由背景和观测误差方差以及背景和观测误差相关性确定，这些都是必需的输入。 
- 误差方差与相关性：用户需提供背景误差方差和观测误差方差（通常是根据背景和观测数据估计的全局常数），观测误差相关性通常假定为 0。背景误差相关性根据输出像元和观测点之间的距离以及所需的相关长度（C）计算得出，C 以输入背景数据的空间参考单位表示，C 值越高，对距离输出像元较远的点的影响越大。
## 技术细节 
- 观测点映射：假设背景图像有 N 个像素，观测数据有 M 个点，通过计算每个像素中的平均点值（和平均点误差，如果可用）将观测点映射到图像像素。 
- 观测权重计算： 
  $$
  W=(Pb)(R + Pb)^{-1}
  $$
  其中，W 是 alpha 权重的 $n*n$ 列，Pb 是背景相关$r(k,j)$ 值（像素对其相邻像素的影响）的$n*n$ 矩阵($n$ 限制为 7 以加快矩阵求逆)，$R$ 是观测误差值的$n*n$ 对角线矩阵（假设每个观测误差彼此独立）。 
- 背景相关$r(k,j)$ 值计算：
  $$
  r(k,j)=e^{-(d(k,j)^2/C)}
  $$
   其中$d(k,j)^2$ 是像素之间的距离，C 是输入的 Background Error Correlation Length 值。
- 输出计算：
  $$
  Xa = Xb + W(Xo - Xb)
  $$
   其中$Xa$、$Xb$、$Xo$ 分别是分析、背景、观测值的$n*1$ 列向量，W 是 alpha 权重的$n*n$ 列。

  ## 代码实现示例

  ```python
  import numpy as np
  
  # 背景场（9x9栅格数据）
  x_b = np.array([
      [15, 16, 17, 18, 19, 20, 21, 22, 23],
      [16, 17, 18, 19, 20, 21, 22, 23, 24],
      [17, 18, 19, 20, 21, 22, 23, 24, 25],
      [18, 19, 20, 21, 22, 23, 24, 25, 26],
      [19, 20, 21, 22, 23, 24, 25, 26, 27],
      [20, 21, 22, 23, 24, 25, 26, 27, 28],
      [21, 22, 23, 24, 25, 26, 27, 28, 29],
      [22, 23, 24, 25, 26, 27, 28, 29, 30],
      [23, 24, 25, 26, 27, 28, 29, 30, 31]
  ])
  
  observations = np.array([20, 26, 32])  
  obs_positions = [(2, 2), (5, 5), (8, 8)]  
  
  # 观测算子 H
  H = np.zeros((3, 81))
  for i, (row, col) in enumerate(obs_positions):
      H[i, row * 9 + col] = 1
  
  B = np.eye(81) * 2
  for i in range(81):
      if i % 9 != 8:  
          B[i, i + 1] = 0.5
          B[i + 1, i] = 0.5
      if i < 72:  
          B[i, i + 9] = 0.5
          B[i + 9, i] = 0.5
  
  # 观测误差协方差矩阵 R
  R = np.eye(3)
  
  # 计算增益矩阵 K
  HBH_T = H @ B @ H.T
  K = B @ H.T @ np.linalg.inv(HBH_T + R)
  
  x_b_vector = x_b.flatten()
  
  y = observations
  x_a_vector = x_b_vector + K @ (y - H @ x_b_vector)
  x_a = x_a_vector.reshape((9, 9))
  
  print("分析场：")
  print(x_a - x_b)
  print(B)
  
  ```

  

